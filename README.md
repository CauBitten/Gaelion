# Gaelion üõ°Ô∏è
Gaelion protects the language model from malicious prompts

## Sistema de Detec√ß√£o Preventiva de Prompts Maliciosos
### Objetivo
- Detectar e bloquear prompts maliciosos antes que cheguem ao modelo de linguagem.
- Reduzir riscos de jailbreak, vazamento de conte√∫do sens√≠vel e manipula√ß√£o intencional.
- Aumentar a seguran√ßa de sistemas de IA usando uma arquitetura h√≠brida eficiente.

### Contribui√ß√µes
- Arquitetura que combina detectores leves locais + classificadores robustos sob demanda.
- Redu√ß√£o de falsos positivos/negativos via ensemble de modelos avaliadores.
- Menor custo computacional gra√ßas √† ativa√ß√£o seletiva de modelos maiores.
- Foco em detectar inten√ß√£o maliciosa, n√£o apenas filtrar conte√∫do gerado.
- Uso de treinamento adversarial e an√°lise contextual para identificar ataques sutis.
- Sa√≠das estruturadas: escores de risco, motivos interpret√°veis, tokens suspeitos.

## Como executar o projeto
...

## Roadmap de Implementa√ß√£o
- 28/11 ‚Äî 30/11: Defini√ß√£o da arquitetura e organiza√ß√£o do reposit√≥rio.
- 01/12 ‚Äî 03/12: Implementa√ß√£o do detector leve e calibra√ß√£o inicial.
- 04/12 ‚Äî 05/12: Cria√ß√£o do medidor de risco e defini√ß√£o dos limiares.
- 06/12 ‚Äî 07/12: Integra√ß√£o do classificador robusto + ensemble.
- 08/12: Constru√ß√£o da API e integra√ß√£o completa do pipeline.
- 09/12: Testes adversariais, ajustes e valida√ß√£o.
- 10/12: Documenta√ß√£o final e prepara√ß√£o para entrega.
